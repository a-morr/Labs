{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Facial Recognition\n",
    "###A basic approach to facial recognition using the SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###The code\n",
    "First and most importantly, import statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy import linalg as la\n",
    "from os import walk\n",
    "from scipy.ndimage import imread\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code to load the database of images, as well as some functions to show the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFaces(path='./faces94'):\n",
    "    \"\"\"Traverse the directory specified by 'path' and return an array containing\n",
    "    one column vector per subdirectory.\n",
    "    \"\"\"\n",
    "    # Traverse the directory and get one image per subdirectory\n",
    "    faces = []\n",
    "    for (dirpath, dirnames, filenames) in walk(path):\n",
    "        for f in filenames:\n",
    "            if f[-3:]==\"jpg\": # only get jpg images\n",
    "                # load image, convert to grayscale, flatten into vector\n",
    "                face = imread(dirpath+\"/\"+f).mean(axis=2).ravel()\n",
    "                faces.append(face)\n",
    "                break\n",
    "    # put all the face vectors column-wise into a matrix\n",
    "    return np.array(faces).T\n",
    "\n",
    "def show(im, w=200, h=180):\n",
    "    \"\"\"Plot the flattened grayscale image 'im' of width 'w' and height 'h'.\"\"\"\n",
    "    plt.imshow(im.reshape((w,h)), cmap=cm.Greys_r)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "def show2(test_image, result, w=200, h=180):\n",
    "    \"\"\"Convenience function for plotting two flattened grayscale images of\n",
    "    the specified width and height side by side\n",
    "    \"\"\"\n",
    "    plt.subplot(121)\n",
    "    plt.title(\"Inputed Image\")\n",
    "    plt.imshow(test_image.reshape((w,h)), cmap=cm.Greys_r)\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(122)\n",
    "    plt.title(\"Closest Match\")\n",
    "    plt.imshow(result.reshape((w,h)), cmap=cm.Greys_r)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display one of the faces to make sure this is working correctly. There should be 153 in all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = getFaces()\n",
    "print(\"Number of faces: {}\".format(images.shape[1]))\n",
    "show(images[:,25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FacialRec class contains all of the methods and variables for our facial recognition system. We will run through each of the methods below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FacialRec:\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        self.initFaces(path)\n",
    "        self.initMeanImage()\n",
    "        self.initDifferences()\n",
    "        self.initEigenfaces()\n",
    "        \n",
    "    def initFaces(self, path):\n",
    "        self.F = getFaces(path)\n",
    "        \n",
    "    def initMeanImage(self):\n",
    "        self.mu = np.mean(self.F, axis=1)\n",
    "        \n",
    "    def initDifferences(self):\n",
    "        self.Fbar = self.F - np.vstack(self.mu)\n",
    "        \n",
    "    def initEigenfaces(self):\n",
    "        self.U, s, Vt = la.svd(self.Fbar, full_matrices = False)\n",
    "        \n",
    "    def project(self, A, s=38):\n",
    "        return self.U[:,:s].T.dot(A)\n",
    "    \n",
    "    def findNearest(self, image, s=38):\n",
    "        Fhat = self.U[:,:s].T.dot(self.Fbar)\n",
    "        ghat = self.U[:,:s].T.dot(image - np.vstack(self.mu))\n",
    "        return np.argmin(np.linalg.norm(Fhat - ghat, axis=0), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###The mean face\n",
    "After retrieving one face image of each person, the mean face is the average of all 153 faces. We create an instance of the FacialRec class and display the mean face below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "facialRec = FacialRec('./faces94')\n",
    "show(facialRec.mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Shifting by the mean\n",
    "This algorithm requires that the data be centered at zero. This can be thought of as accentuating the unique features of each face. To center the data at zero, we have to shift each of our sample faces by the mean face. Below is displayed the 25th face and the same face after shifting by the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title(\"Original face\")\n",
    "show(facialRec.F[:,24])\n",
    "plt.title(\"Mean-shifted\")\n",
    "show(facialRec.Fbar[:,24])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Eigenfaces\n",
    "We use the SVD to reduce the dimensionality of our data. By projecting to an $s$-dimensional subspace, instead of storing and comparing $200 \\times 180$ values for each face image we only need $s$ values. \n",
    "The new subspace we project to is determined by the SVD of $\\bar{F}$.\n",
    "Basis vectors of this subspace are called \"eigenfaces\".\n",
    "We represent the image by its coordinate vector - this contains the coefficients in the linear combination of eigenfaces that makes up this particular face.\n",
    "\n",
    " Below is displayed the first basis vector or eigenface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show(facialRec.U[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Representing a face with fewer dimensions\n",
    "We can project a face into the $s$ dimensional subspace, store it as a length-$s$ coordinate vector, and then \"rebuild\" it from the eigenfaces. Below we show the first face in the dataset rebuilt with $s = 5, 9, 19, 38,$ and $75$ eigenfaces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in [5,9,19,38,75,153]:\n",
    "    face = facialRec.Fbar[:,0]\n",
    "    first_s = facialRec.project(face, s = s)\n",
    "    standard = np.dot(facialRec.U[:,:s],first_s)\n",
    "    result = standard + facialRec.mu\n",
    "    plt.title(\"s = {}\".format(s))\n",
    "    show(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Recognizing a face\n",
    "To perform facial recognition, we project an unknown face image to the $s$ dimensional subspace. We compare its coordinate vector with the coordinate vectors of faces that we have already seen. We then return the closest match.\n",
    "\n",
    "Below we randomly select 5 faces and find the closest match for each. We use $s = 38$ eigenfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sampleFaces(n_tests, path=\"./faces94\"):\n",
    "    \"\"\"Return an array containing a sample of n_tests images contained\n",
    "    in the path as flattened images in the columns of the output\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for (dirpath, dirnames, filenames) in walk(path):\n",
    "        for f in filenames:\n",
    "            if f[-3:]==\"jpg\": # only get jpg images\n",
    "                files.append(dirpath+\"/\"+f)\n",
    "\n",
    "    #Get a sample of the images\n",
    "    test_files = random.sample(files, n_tests)\n",
    "    #Flatten and average the pixel values\n",
    "    images = np.array([imread(f).mean(axis=2).ravel() for f in test_files]).T\n",
    "    return images\n",
    "\n",
    "for i in xrange(5):\n",
    "    test_image = sampleFaces(1)    \n",
    "    i = facialRec.findNearest(test_image, s=38)\n",
    "    show2(test_image, facialRec.F[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
